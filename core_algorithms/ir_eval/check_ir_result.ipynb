{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# kaggle_df = pd.read_csv('kaggle_dataset_df_page500.csv')\n",
    "# print(kaggle_df.shape[0])\n",
    "# kaggle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5627\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>owner</th>\n",
       "      <th>date</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>keywords</th>\n",
       "      <th>#downloads</th>\n",
       "      <th>#views</th>\n",
       "      <th>#votes</th>\n",
       "      <th>dataset_slug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>The **MNIST** database (**Modified National In...</td>\n",
       "      <td>https://paperswithcode.com/dataset/mnist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>CelebFaces Attributes dataset contains 202,599...</td>\n",
       "      <td>https://paperswithcode.com/dataset/celeba</td>\n",
       "      <td>01/01/2015</td>\n",
       "      <td>CelebFaces Attributes Dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JFT-300M</td>\n",
       "      <td>**JFT-300M** is an internal Google dataset use...</td>\n",
       "      <td>https://paperswithcode.com/dataset/jft-300m</td>\n",
       "      <td>10/07/2017</td>\n",
       "      <td>JFT-300M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLUE</td>\n",
       "      <td>General Language Understanding Evaluation (**G...</td>\n",
       "      <td>https://paperswithcode.com/dataset/glue</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>General Language Understanding Evaluation benc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultiNLI</td>\n",
       "      <td>The **Multi-Genre Natural Language Inference**...</td>\n",
       "      <td>https://paperswithcode.com/dataset/multinli</td>\n",
       "      <td>01/01/2018</td>\n",
       "      <td>Multi-Genre Natural Language Inference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>Dataset for the Article \"Does the Venue of Sci...</td>\n",
       "      <td>Is there any correlation between the impact of...</td>\n",
       "      <td>https://paperswithcode.com/dataset/dataset-for...</td>\n",
       "      <td>31/05/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5623</th>\n",
       "      <td>WSJ Dow Jones Stock Data</td>\n",
       "      <td>Please see code repository. [https://github.co...</td>\n",
       "      <td>https://paperswithcode.com/dataset/wsj-dow-jon...</td>\n",
       "      <td>15/02/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624</th>\n",
       "      <td>ZInd</td>\n",
       "      <td>The Zillow Indoor Dataset (ZInD) provides exte...</td>\n",
       "      <td>https://paperswithcode.com/dataset/zind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zillow Indoor Dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>IMDB-Clean</td>\n",
       "      <td>We have cleaned the noisy IMDB-WIKI dataset us...</td>\n",
       "      <td>https://paperswithcode.com/dataset/imdb-clean</td>\n",
       "      <td>21/06/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>TriggerCit 2021 Thailand / Nepal floods</td>\n",
       "      <td>Twitter dataset related to flood events onsets...</td>\n",
       "      <td>https://paperswithcode.com/dataset/triggercit-...</td>\n",
       "      <td>24/02/2022</td>\n",
       "      <td>Twitter dataset of flood-related images for Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5627 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                                                 MNIST   \n",
       "1                                                CelebA   \n",
       "2                                              JFT-300M   \n",
       "3                                                  GLUE   \n",
       "4                                              MultiNLI   \n",
       "...                                                 ...   \n",
       "5622  Dataset for the Article \"Does the Venue of Sci...   \n",
       "5623                           WSJ Dow Jones Stock Data   \n",
       "5624                                               ZInd   \n",
       "5625                                         IMDB-Clean   \n",
       "5626            TriggerCit 2021 Thailand / Nepal floods   \n",
       "\n",
       "                                            description  \\\n",
       "0     The **MNIST** database (**Modified National In...   \n",
       "1     CelebFaces Attributes dataset contains 202,599...   \n",
       "2     **JFT-300M** is an internal Google dataset use...   \n",
       "3     General Language Understanding Evaluation (**G...   \n",
       "4     The **Multi-Genre Natural Language Inference**...   \n",
       "...                                                 ...   \n",
       "5622  Is there any correlation between the impact of...   \n",
       "5623  Please see code repository. [https://github.co...   \n",
       "5624  The Zillow Indoor Dataset (ZInD) provides exte...   \n",
       "5625  We have cleaned the noisy IMDB-WIKI dataset us...   \n",
       "5626  Twitter dataset related to flood events onsets...   \n",
       "\n",
       "                                                  owner        date  \\\n",
       "0              https://paperswithcode.com/dataset/mnist         NaN   \n",
       "1             https://paperswithcode.com/dataset/celeba  01/01/2015   \n",
       "2           https://paperswithcode.com/dataset/jft-300m  10/07/2017   \n",
       "3               https://paperswithcode.com/dataset/glue  01/01/2019   \n",
       "4           https://paperswithcode.com/dataset/multinli  01/01/2018   \n",
       "...                                                 ...         ...   \n",
       "5622  https://paperswithcode.com/dataset/dataset-for...  31/05/2021   \n",
       "5623  https://paperswithcode.com/dataset/wsj-dow-jon...  15/02/2022   \n",
       "5624            https://paperswithcode.com/dataset/zind         NaN   \n",
       "5625      https://paperswithcode.com/dataset/imdb-clean  21/06/2021   \n",
       "5626  https://paperswithcode.com/dataset/triggercit-...  24/02/2022   \n",
       "\n",
       "                                               subtitle  keywords  #downloads  \\\n",
       "0                                                   NaN       NaN         NaN   \n",
       "1                         CelebFaces Attributes Dataset       NaN         NaN   \n",
       "2                                              JFT-300M       NaN         NaN   \n",
       "3     General Language Understanding Evaluation benc...       NaN         NaN   \n",
       "4                Multi-Genre Natural Language Inference       NaN         NaN   \n",
       "...                                                 ...       ...         ...   \n",
       "5622                                                NaN       NaN         NaN   \n",
       "5623                                                NaN       NaN         NaN   \n",
       "5624                              Zillow Indoor Dataset       NaN         NaN   \n",
       "5625                                                NaN       NaN         NaN   \n",
       "5626  Twitter dataset of flood-related images for Se...       NaN         NaN   \n",
       "\n",
       "      #views  #votes  dataset_slug  \n",
       "0        NaN     NaN           NaN  \n",
       "1        NaN     NaN           NaN  \n",
       "2        NaN     NaN           NaN  \n",
       "3        NaN     NaN           NaN  \n",
       "4        NaN     NaN           NaN  \n",
       "...      ...     ...           ...  \n",
       "5622     NaN     NaN           NaN  \n",
       "5623     NaN     NaN           NaN  \n",
       "5624     NaN     NaN           NaN  \n",
       "5625     NaN     NaN           NaN  \n",
       "5626     NaN     NaN           NaN  \n",
       "\n",
       "[5627 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paperwithcode_df = pd.read_csv('paperwithcode_df.csv')\n",
    "# print(paperwithcode_df.shape[0])\n",
    "# paperwithcode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_bm_25_result_df_statist_health.csv\r\n",
      "paper_bm_25_result_df_stock_predict.csv\r\n",
      "paper_bm_25_result_df_vision_transform.csv\r\n",
      "paper_bm_25_result_df_walid_magdi.csv\r\n",
      "paper_tfidf_result_df_statist_health.csv\r\n",
      "paper_tfidf_result_df_stock_predict.csv\r\n",
      "paper_tfidf_result_df_vision_transform.csv\r\n",
      "paper_tfidf_result_df_walid_magdi.csv\r\n",
      "phrase_result_df_statist_health.csv\r\n",
      "phrase_result_df_stock_predict.csv\r\n",
      "phrase_result_df_vision_transform.csv\r\n",
      "phrase_result_df_walid_magdi.csv\r\n",
      "proximity_df_statist_health.csv\r\n",
      "proximity_df_stock_predict.csv\r\n",
      "proximity_df_vision_transform.csv\r\n",
      "proximity_df_walid_magdi.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls result/paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment on \"A sensitivity study of the primary correlators used to\n",
      "  characterize chiral-magnetically-driven charge separation'' by Magdy, Nie,\n",
      "  Ma, and Lacey\n",
      "Renormalization Group and Problem of Radiation\n",
      "\n",
      "Comment on \"A sensitivity study of the primary correlators used to\n",
      "  characterize chiral-magnetically-driven charge separation'' by Magdy, Nie,\n",
      "  Ma, and Lacey\n",
      "Renormalization Group and Problem of Radiation\n"
     ]
    }
   ],
   "source": [
    "bm25_res = pd.read_csv('result/paper/paper_bm_25_result_df_walid_magdi.csv')\n",
    "tfidf_res = pd.read_csv('result/paper/paper_tfidf_result_df_walid_magdi.csv')\n",
    "for i in range(min(10, len(bm25_res))):\n",
    "    print(bm25_res.iloc[i, 0])\n",
    "print()\n",
    "for i in range(min(10, len(tfidf_res))):\n",
    "    print(tfidf_res.iloc[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texture-Based Methods for Analyzing Elementary Visual Substances.\n",
      "Curvature of visual space under vertical eye rotation: implications for spatial vision and visuomotor control.\n",
      "Adaptive filtering in spatial vision: evidence from feature marking in plaids.\n",
      "The myth of upright vision. A psychophysical and functional imaging study of adaptation to inverting spectacles.\n",
      "Achieving results through transformational leadership.\n",
      "Seeing in three dimensions: the neurophysiology of stereopsis.\n",
      "Hospital transformation and organisational learning.\n",
      "Asymmetric color matching: how color appearance depends on the illuminant.\n",
      "Saving your career in the 21st century.\n",
      "The importance of vitamin A in nutrition.\n",
      "\n",
      "Texture-Based Methods for Analyzing Elementary Visual Substances.\n",
      "Transformation of Acetobacter xylinum with plasmid DNA by electroporation.\n",
      "Curvature of visual space under vertical eye rotation: implications for spatial vision and visuomotor control.\n",
      "Identification and quantification of a carcinogen-induced molecular initiation event in cell transformation.\n",
      "Nonmyristoylated Abl proteins transform a factor-dependent hematopoietic cell line.\n",
      "Rat embryo cells immortalized with transfected oncogenes are transformed by gamma irradiation.\n",
      "Interleukin-1 production by transformed fibroblasts. II. Influence on antigen presentation and T-cell-mediated anti-tumor response.\n",
      "Adaptive filtering in spatial vision: evidence from feature marking in plaids.\n",
      "The myth of upright vision. A psychophysical and functional imaging study of adaptation to inverting spectacles.\n",
      "Cooperation between the H-ras oncogene and a truncated derivative of the v-myb oncogene in transformation of hamster embryo fibroblasts.\n"
     ]
    }
   ],
   "source": [
    "bm25_res = pd.read_csv('result/paper/paper_bm_25_result_df_vision_transform.csv')\n",
    "tfidf_res = pd.read_csv('result/paper/paper_tfidf_result_df_vision_transform.csv')\n",
    "for i in range(10):\n",
    "    print(bm25_res.iloc[i, 0])\n",
    "print()\n",
    "for i in range(10):\n",
    "    print(tfidf_res.iloc[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vision Transformers with Patch Diversification\n",
      "Focal Attention for Long-Range Interactions in Vision Transformers\n",
      "Focal Self-attention for Local-Global Interactions in Vision\n",
      "  Transformers\n",
      "CvT: Introducing Convolutions to Vision Transformers\n",
      "On the Robustness of Vision Transformers to Adversarial Examples\n",
      "SiT: Self-supervised vIsion Transformer\n",
      "Pale Transformer: A General Vision Transformer Backbone with Pale-Shaped\n",
      "  Attention\n",
      "ATS: Adaptive Token Sampling For Efficient Vision Transformers\n",
      "A Survey on Vision Transformer\n",
      "Glance-and-Gaze Vision Transformer\n"
     ]
    }
   ],
   "source": [
    "phrase_df = pd.read_csv('result/paper/phrase_result_df_walid_magdi.csv')\n",
    "for i in range(min(10, phrase_df.shape[0])):\n",
    "    print(phrase_df.iloc[i, 0])\n",
    "    \n",
    "print()\n",
    "phrase_df = pd.read_csv('result/paper/phrase_result_df_vision_transform.csv')\n",
    "for i in range(min(10, phrase_df.shape[0])):\n",
    "    print(phrase_df.iloc[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proximity_df= pd.read_csv('result/paper/proximity_df_walid_magdi.csv')\n",
    "for i in range(min(10, proximity_df.shape[0])):\n",
    "    print(proximity_df.iloc[i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
