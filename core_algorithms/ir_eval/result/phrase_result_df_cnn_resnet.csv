title,abstract,id
"NLP-CUET@DravidianLangTech-EACL2021: Investigating Visual and Textual
  Features to Identify Trolls from Multimodal Social Media Memes","  In the past few years, the meme has become a new way of communication on the
Internet. As memes are the images with embedded text, it can quickly spread
hate, offence and violence. Classifying memes are very challenging because of
their multimodal nature and region-specific interpretation. A shared task is
organized to develop models that can identify trolls from multimodal social
media memes. This work presents a computational model that we have developed as
part of our participation in the task. Training data comes in two forms: an
image with embedded Tamil code-mixed text and an associated caption given in
English. We investigated the visual and textual features using CNN, VGG16,
Inception, Multilingual-BERT, XLM-Roberta, XLNet models. Multimodal features
are extracted by combining image (CNN, ResNet50, Inception) and text (Long
short term memory network) features via early fusion approach. Results indicate
that the textual approach with XLNet achieved the highest weighted $f_1$-score
of $0.58$, which enabled our model to secure $3^{rd}$ rank in this task.
",a
"How does topology influence gradient propagation and model performance
  of deep networks with DenseNet-type skip connections?","  DenseNets introduce concatenation-type skip connections that achieve
state-of-the-art accuracy in several computer vision tasks. In this paper, we
reveal that the topology of the concatenation-type skip connections is closely
related to the gradient propagation which, in turn, enables a predictable
behavior of DNNs' test performance. To this end, we introduce a new metric
called NN-Mass to quantify how effectively information flows through DNNs.
Moreover, we empirically show that NN-Mass also works for other types of skip
connections, e.g., for ResNets, Wide-ResNets (WRNs), and MobileNets, which
contain addition-type skip connections (i.e., residuals or inverted residuals).
As such, for both DenseNet-like CNNs and ResNets/WRNs/MobileNets, our
theoretically grounded NN-Mass can identify models with similar accuracy,
despite having significantly different size/compute requirements. Detailed
experiments on both synthetic and real datasets (e.g., MNIST, CIFAR-10,
CIFAR-100, ImageNet) provide extensive evidence for our insights. Finally, the
closed-form equation of our NN-Mass enables us to design significantly
compressed DenseNets (for CIFAR-10) and MobileNets (for ImageNet) directly at
initialization without time-consuming training and/or searching.
",a
"Reliable Tuberculosis Detection using Chest X-ray with Deep Learning,
  Segmentation and Visualization","  Tuberculosis (TB) is a chronic lung disease that occurs due to bacterial
infection and is one of the top 10 leading causes of death. Accurate and early
detection of TB is very important, otherwise, it could be life-threatening. In
this work, we have detected TB reliably from the chest X-ray images using image
pre-processing, data augmentation, image segmentation, and deep-learning
classification techniques. Several public databases were used to create a
database of 700 TB infected and 3500 normal chest X-ray images for this study.
Nine different deep CNNs (ResNet18, ResNet50, ResNet101, ChexNet, InceptionV3,
Vgg19, DenseNet201, SqueezeNet, and MobileNet), which were used for transfer
learning from their pre-trained initial weights and trained, validated and
tested for classifying TB and non-TB normal cases. Three different experiments
were carried out in this work: segmentation of X-ray images using two different
U-net models, classification using X-ray images, and segmented lung images. The
accuracy, precision, sensitivity, F1-score, specificity in the detection of
tuberculosis using X-ray images were 97.07 %, 97.34 %, 97.07 %, 97.14 % and
97.36 % respectively. However, segmented lungs for the classification
outperformed than whole X-ray image-based classification and accuracy,
precision, sensitivity, F1-score, specificity were 99.9 %, 99.91 %, 99.9 %,
99.9 %, and 99.52 % respectively. The paper also used a visualization technique
to confirm that CNN learns dominantly from the segmented lung regions results
in higher detection accuracy. The proposed method with state-of-the-art
performance can be useful in the computer-aided faster diagnosis of
tuberculosis.
",a
"On Tighter Generalization Bounds for Deep Neural Networks: CNNs, ResNets, and Beyond","We propose a generalization error bound for a general family of deep neural networks based on the depth and width of the networks, as well as the spectral norm of weight matrices. Through introducing a novel characterization of the Lipschitz properties of neural network family, we achieve a tighter generalization error bound. We further obtain a result that is free of linear dependence on norms for bounded losses. Besides the general deep neural networks, our results can be applied to derive new bounds for several popular architectures, including convolutional neural networks (CNNs), residual networks (ResNets), and hyperspherical networks (SphereNets).  When achieving same generalization errors with previous arts, our bounds allow for the choice of much larger parameter spaces of weight matrices, inducing potentially stronger expressive ability for neural networks.",p
Age and Gender Prediction using Deep CNNs and Transfer Learning,"  The last decade or two has witnessed a boom of images. With the increasing
ubiquity of cameras and with the advent of selfies, the number of facial images
available in the world has skyrocketed. Consequently, there has been a growing
interest in automatic age and gender prediction of a person using facial
images. We in this paper focus on this challenging problem. Specifically, this
paper focuses on age estimation, age classification and gender classification
from still facial images of an individual. We train different models for each
problem and we also draw comparisons between building a custom CNN
(Convolutional Neural Network) architecture and using various CNN architectures
as feature extractors, namely VGG16 pre-trained on VGGFace, Res-Net50 and
SE-ResNet50 pre-trained on VGGFace2 dataset and training over those extracted
features. We also provide baseline performance of various machine learning
algorithms on the feature extraction which gave us the best results. It was
observed that even simple linear regression trained on such extracted features
outperformed training CNN, ResNet50 and ResNeXt50 from scratch for age
estimation.
",a
Spatiotemporal CNNs for Pornography Detection in Videos,"  With the increasing use of social networks and mobile devices, the number of
videos posted on the Internet is growing exponentially. Among the inappropriate
contents published on the Internet, pornography is one of the most worrying as
it can be accessed by teens and children. Two spatiotemporal CNNs, VGG-C3D CNN
and ResNet R(2+1)D CNN, were assessed for pornography detection in videos in
the present study. Experimental results using the Pornography-800 dataset
showed that these spatiotemporal CNNs performed better than some
state-of-the-art methods based on bag of visual words and are competitive with
other CNN-based approaches, reaching accuracy of 95.1%.
",a
Constrained Linear Data-feature Mapping for Image Classification,"  In this paper, we propose a constrained linear data-feature mapping model as
an interpretable mathematical model for image classification using
convolutional neural network (CNN) such as the ResNet. From this viewpoint, we
establish the detailed connections in a technical level between the traditional
iterative schemes for constrained linear system and the architecture for the
basic blocks of ResNet. Under these connections, we propose some natural
modifications of ResNet type models which will have less parameters but still
maintain almost the same accuracy as these corresponding original models. Some
numerical experiments are shown to demonstrate the validity of this constrained
learning data-feature mapping assumption.
",a
"ELoPE: Fine-Grained Visual Classification with Efficient Localization,
  Pooling and Embedding","  The task of fine-grained visual classification (FGVC) deals with
classification problems that display a small inter-class variance such as
distinguishing between different bird species or car models. State-of-the-art
approaches typically tackle this problem by integrating an elaborate attention
mechanism or (part-) localization method into a standard convolutional neural
network (CNN). Also in this work the aim is to enhance the performance of a
backbone CNN such as ResNet by including three efficient and lightweight
components specifically designed for FGVC. This is achieved by using global
k-max pooling, a discriminative embedding layer trained by optimizing class
means and an efficient bounding box estimator that only needs class labels for
training. The resulting model achieves new best state-of-the-art recognition
accuracies on the Stanford cars and FGVC-Aircraft datasets.
",a
A Study of Compositional Generalization in Neural Models,"  Compositional and relational learning is a hallmark of human intelligence,
but one which presents challenges for neural models. One difficulty in the
development of such models is the lack of benchmarks with clear compositional
and relational task structure on which to systematically evaluate them. In this
paper, we introduce an environment called ConceptWorld, which enables the
generation of images from compositional and relational concepts, defined using
a logical domain specific language. We use it to generate images for a variety
of compositional structures: 2x2 squares, pentominoes, sequences, scenes
involving these objects, and other more complex concepts. We perform
experiments to test the ability of standard neural architectures to generalize
on relations with compositional arguments as the compositional depth of those
arguments increases and under substitution. We compare standard neural networks
such as MLP, CNN and ResNet, as well as state-of-the-art relational networks
including WReN and PrediNet in a multi-class image classification setting. For
simple problems, all models generalize well to close concepts but struggle with
longer compositional chains. For more complex tests involving substitutivity,
all models struggle, even with short chains. In highlighting these difficulties
and providing an environment for further experimentation, we hope to encourage
the development of models which are able to generalize effectively in
compositional, relational domains.
",a
Improved Knowledge Distillation via Teacher Assistant,"  Despite the fact that deep neural networks are powerful models and achieve
appealing results on many tasks, they are too large to be deployed on edge
devices like smartphones or embedded sensor nodes. There have been efforts to
compress these networks, and a popular method is knowledge distillation, where
a large (teacher) pre-trained network is used to train a smaller (student)
network. However, in this paper, we show that the student network performance
degrades when the gap between student and teacher is large. Given a fixed
student network, one cannot employ an arbitrarily large teacher, or in other
words, a teacher can effectively transfer its knowledge to students up to a
certain size, not smaller. To alleviate this shortcoming, we introduce
multi-step knowledge distillation, which employs an intermediate-sized network
(teacher assistant) to bridge the gap between the student and the teacher.
Moreover, we study the effect of teacher assistant size and extend the
framework to multi-step distillation. Theoretical analysis and extensive
experiments on CIFAR-10,100 and ImageNet datasets and on CNN and ResNet
architectures substantiate the effectiveness of our proposed approach.
",a
"Mitigating severe over-parameterization in deep convolutional neural
  networks through forced feature abstraction and compression with an
  entropy-based heuristic","  Convolutional Neural Networks (CNNs) such as ResNet-50, DenseNet-40 and
ResNeXt-56 are severely over-parameterized, necessitating a consequent increase
in the computational resources required for model training which scales
exponentially for increments in model depth. In this paper, we propose an
Entropy-Based Convolutional Layer Estimation (EBCLE) heuristic which is robust
and simple, yet effective in resolving the problem of over-parameterization
with regards to network depth of CNN model. The EBCLE heuristic employs a
priori knowledge of the entropic data distribution of input datasets to
determine an upper bound for convolutional network depth, beyond which identity
transformations are prevalent offering insignificant contributions for
enhancing model performance. Restricting depth redundancies by forcing feature
compression and abstraction restricts over-parameterization while decreasing
training time by 24.99% - 78.59% without degradation in model performance. We
present empirical evidence to emphasize the relative effectiveness of broader,
yet shallower models trained using the EBCLE heuristic, which maintains or
outperforms baseline classification accuracies of narrower yet deeper models.
The EBCLE heuristic is architecturally agnostic and EBCLE based CNN models
restrict depth redundancies resulting in enhanced utilization of the available
computational resources. The proposed EBCLE heuristic is a compelling technique
for researchers to analytically justify their HyperParameter (HP) choices for
CNNs. Empirical validation of the EBCLE heuristic in training CNN models was
established on five benchmarking datasets (ImageNet32, CIFAR-10/100, STL-10,
MNIST) and four network architectures (DenseNet, ResNet, ResNeXt and
EfficientNet B0-B2) with appropriate statistical tests employed to infer any
conclusive claims presented in this paper.
",a
L4: Practical loss-based stepsize adaptation for deep learning,"  We propose a stepsize adaptation scheme for stochastic gradient descent. It
operates directly with the loss function and rescales the gradient in order to
make fixed predicted progress on the loss. We demonstrate its capabilities by
conclusively improving the performance of Adam and Momentum optimizers. The
enhanced optimizers with default hyperparameters consistently outperform their
constant stepsize counterparts, even the best ones, without a measurable
increase in computational cost. The performance is validated on multiple
architectures including dense nets, CNNs, ResNets, and the recurrent
Differential Neural Computer on classical datasets MNIST, fashion MNIST,
CIFAR10 and others.
",a
Stochastic Anderson Mixing for Nonconvex Stochastic Optimization,"  Anderson mixing (AM) is an acceleration method for fixed-point iterations.
Despite its success and wide usage in scientific computing, the convergence
theory of AM remains unclear, and its applications to machine learning problems
are not well explored. In this paper, by introducing damped projection and
adaptive regularization to classical AM, we propose a Stochastic Anderson
Mixing (SAM) scheme to solve nonconvex stochastic optimization problems. Under
mild assumptions, we establish the convergence theory of SAM, including the
almost sure convergence to stationary points and the worst-case iteration
complexity. Moreover, the complexity bound can be improved when randomly
choosing an iterate as the output. To further accelerate the convergence, we
incorporate a variance reduction technique into the proposed SAM. We also
propose a preconditioned mixing strategy for SAM which can empirically achieve
faster convergence or better generalization ability. Finally, we apply the SAM
method to train various neural networks including the vanilla CNN, ResNets,
WideResNet, ResNeXt, DenseNet and RNN. Experimental results on image
classification and language model demonstrate the advantages of our method.
",a
Soft Threshold Weight Reparameterization for Learnable Sparsity,"  Sparsity in Deep Neural Networks (DNNs) is studied extensively with the focus
of maximizing prediction accuracy given an overall parameter budget. Existing
methods rely on uniform or heuristic non-uniform sparsity budgets which have
sub-optimal layer-wise parameter allocation resulting in a) lower prediction
accuracy or b) higher inference cost (FLOPs). This work proposes Soft Threshold
Reparameterization (STR), a novel use of the soft-threshold operator on DNN
weights. STR smoothly induces sparsity while learning pruning thresholds
thereby obtaining a non-uniform sparsity budget. Our method achieves
state-of-the-art accuracy for unstructured sparsity in CNNs (ResNet50 and
MobileNetV1 on ImageNet-1K), and, additionally, learns non-uniform budgets that
empirically reduce the FLOPs by up to 50%. Notably, STR boosts the accuracy
over existing results by up to 10% in the ultra sparse (99%) regime and can
also be used to induce low-rank (structured sparsity) in RNNs. In short, STR is
a simple mechanism which learns effective sparsity budgets that contrast with
popular heuristics. Code, pretrained models and sparsity budgets are at
https://github.com/RAIVNLab/STR.
",a
"On Tighter Generalization Bound for Deep Neural Networks: CNNs, ResNets,
  and Beyond","  We establish a margin based data dependent generalization error bound for a
general family of deep neural networks in terms of the depth and width, as well
as the Jacobian of the networks. Through introducing a new characterization of
the Lipschitz properties of neural network family, we achieve significantly
tighter generalization bounds than existing results. Moreover, we show that the
generalization bound can be further improved for bounded losses. Aside from the
general feedforward deep neural networks, our results can be applied to derive
new bounds for popular architectures, including convolutional neural networks
(CNNs) and residual networks (ResNets). When achieving same generalization
errors with previous arts, our bounds allow for the choice of larger parameter
spaces of weight matrices, inducing potentially stronger expressive ability for
neural networks. Numerical evaluation is also provided to support our theory.
",a
Interpolation between CNNs and ResNets,"Although ordinary differential equations (ODEs) provide insights for designing networks architectures, its relationship with the non-residual convolutional neural networks (CNNs) is still unclear. In this paper, we present a novel ODE model by adding a damping term. It can be shown that the proposed model can recover both a ResNet and a CNN by adjusting an interpolation coefficient. Therefore, the damped ODE model provides a unified framework for the interpretation of CNNs and ResNets. The Lyapunov analysis reveals better stability of the proposed model, and thus yields robustness improvement of the learned networks. Experiments on a number of image classification benchmarks show that the proposed model substantially improves the accuracy of ResNet and ResNeXt over the perturbed inputs from both stochastic noise and adversarial attack methods. Moreover, the loss landscape analysis demonstrates the improved robustness of our method along the attack direction.",p
Reinventing 2D Convolutions for 3D Images,"  There have been considerable debates over 2D and 3D representation learning
on 3D medical images. 2D approaches could benefit from large-scale 2D
pretraining, whereas they are generally weak in capturing large 3D contexts. 3D
approaches are natively strong in 3D contexts, however few publicly available
3D medical dataset is large and diverse enough for universal 3D pretraining.
Even for hybrid (2D + 3D) approaches, the intrinsic disadvantages within the 2D
/ 3D parts still exist. In this study, we bridge the gap between 2D and 3D
convolutions by reinventing the 2D convolutions. We propose ACS
(axial-coronal-sagittal) convolutions to perform natively 3D representation
learning, while utilizing the pretrained weights on 2D datasets. In ACS
convolutions, 2D convolution kernels are split by channel into three parts, and
convoluted separately on the three views (axial, coronal and sagittal) of 3D
representations. Theoretically, ANY 2D CNN (ResNet, DenseNet, or DeepLab) is
able to be converted into a 3D ACS CNN, with pretrained weight of a same
parameter size. Extensive experiments on several medical benchmarks (including
classification, segmentation and detection tasks) validate the consistent
superiority of the pretrained ACS CNNs, over the 2D / 3D CNN counterparts with
/ without pretraining. Even without pretraining, the ACS convolution can be
used as a plug-and-play replacement of standard 3D convolution, with smaller
model size and less computation.
",a
"SE-ECGNet: A Multi-scale Deep Residual Network with
  Squeeze-and-Excitation Module for ECG Signal Classification","  The classification of electrocardiogram (ECG) signals, which takes much time
and suffers from a high rate of misjudgment, is recognized as an extremely
challenging task for cardiologists. The major difficulty of the ECG signals
classification is caused by the long-term sequence dependencies. Most existing
approaches for ECG signal classification use Recurrent Neural Network models,
e.g., LSTM and GRU, which are unable to extract accurate features for such long
sequences. Other approaches utilize 1-Dimensional Convolutional Neural Network
(CNN), such as ResNet or its variant, and they can not make good use of the
multi-lead information from ECG signals.Based on the above observations, we
develop a multi-scale deep residual network for the ECG signal classification
task. We are the first to propose to treat the multi-lead signal as a
2-dimensional matrix and combines multi-scale 2-D convolution blocks with 1-D
convolution blocks for feature extraction. Our proposed model achieves 99.2%
F1-score in the MIT-BIH dataset and 89.4% F1-score in Alibaba dataset and
outperforms the state-of-the-art performance by 2% and 3%, respectively, view
related code and data at https://github.com/Amadeuszhao/SE-ECGNet
",a
"Multi-label Detection and Classification of Red Blood Cells in
  Microscopic Images","  Cell detection and cell type classification from biomedical images play an
important role for high-throughput imaging and various clinical application.
While classification of single cell sample can be performed with standard
computer vision and machine learning methods, analysis of multi-label samples
(region containing congregating cells) is more challenging, as separation of
individual cells can be difficult (e.g. touching cells) or even impossible
(e.g. overlapping cells). As multi-instance images are common in analyzing Red
Blood Cell (RBC) for Sickle Cell Disease (SCD) diagnosis, we develop and
implement a multi-instance cell detection and classification framework to
address this challenge. The framework firstly trains a region proposal model
based on Region-based Convolutional Network (RCNN) to obtain bounding-boxes of
regions potentially containing single or multiple cells from input microscopic
images, which are extracted as image patches. High-level image features are
then calculated from image patches through a pre-trained Convolutional Neural
Network (CNN) with ResNet-50 structure. Using these image features inputs, six
networks are then trained to make multi-label prediction of whether a given
patch contains cells belonging to a specific cell type. As the six networks are
trained with image patches consisting of both individual cells and
touching/overlapping cells, they can effectively recognize cell types that are
presented in multi-instance image samples. Finally, for the purpose of SCD
testing, we train another machine learning classifier to predict whether the
given image patch contains abnormal cell type based on outputs from the six
networks. Testing result of the proposed framework shows that it can achieve
good performance in automatic cell detection and classification.
",a
Small-Footprint Wake Up Word Recognition in Noisy Environments Employing Competing-Words-Based Feature,"This paper proposes a small-footprint wake-up-word (WUW) recognition system for real noisy environments by employing the competing-words-based feature. Competing-words-based features are generated using a ResNet-based deep neural network with small parameters using the competing-words dataset. The competing-words dataset consists of the most acoustically similar and dissimilar words to the WUW used for our system. The obtained features are used as input to the classification network, which is developed using the convolutional neural network (CNN) model. To obtain sufficient data for training, data augmentation is performed by using a room impulse response filter and adding sound signals of various television shows as background noise, which simulates an actual living room environment. The experimental results demonstrate that the proposed WUW recognition system outperforms the baselines that employ CNN and ResNet models. The proposed system shows 1.31% in equal error rate and 1.40% false rejection rate at a 1.0% false alarm rate, which are 29.57% and 50.00% relative improvements compared to the ResNet system, respectively. The number of parameters used for the proposed system is reduced by 83.53% compared to the ResNet system. These results prove that the proposed system with the competing-words-based feature is highly effective at improving WUW recognition performance in noisy environments with a smaller footprint.",p
Capsules with Inverted Dot-Product Attention Routing,"  We introduce a new routing algorithm for capsule networks, in which a child
capsule is routed to a parent based only on agreement between the parent's
state and the child's vote. The new mechanism 1) designs routing via inverted
dot-product attention; 2) imposes Layer Normalization as normalization; and 3)
replaces sequential iterative routing with concurrent iterative routing. When
compared to previously proposed routing algorithms, our method improves
performance on benchmark datasets such as CIFAR-10 and CIFAR-100, and it
performs at-par with a powerful CNN (ResNet-18) with 4x fewer parameters. On a
different task of recognizing digits from overlayed digit images, the proposed
capsule model performs favorably against CNNs given the same number of layers
and neurons per layer. We believe that our work raises the possibility of
applying capsule networks to complex real-world tasks. Our code is publicly
available at: https://github.com/apple/ml-capsules-inverted-attention-routing
An alternative implementation is available at:
https://github.com/yaohungt/Capsules-Inverted-Attention-Routing/blob/master/README.md
",a
"Machine Intelligence-Driven Classification of Cancer Patients-Derived
  Extracellular Vesicles using Fluorescence Correlation Spectroscopy: Results
  from a Pilot Study","  Patient-derived extracellular vesicles (EVs) that contains a complex
biological cargo is a valuable source of liquid biopsy diagnostics to aid in
early detection, cancer screening, and precision nanotherapeutics. In this
study, we predicted that coupling cancer patient blood-derived EVs to
time-resolved spectroscopy and artificial intelligence (AI) could provide a
robust cancer screening and follow-up tools. Methods: Fluorescence correlation
spectroscopy (FCS) measurements were performed on 24 blood samples-derived EVs.
Blood samples were obtained from 15 cancer patients (presenting 5 different
types of cancers), and 9 healthy controls (including patients with benign
lesions). The obtained FCS autocorrelation spectra were processed into power
spectra using the Fast-Fourier Transform algorithm and subjected to various
machine learning algorithms to distinguish cancer spectra from healthy control
spectra. Results and Applications: The performance of AdaBoost Random Forest
(RF) classifier, support vector machine, and multilayer perceptron, were tested
on selected frequencies in the N=118 power spectra. The RF classifier exhibited
a 90% classification accuracy and high sensitivity and specificity in
distinguishing the FCS power spectra of cancer patients from those of healthy
controls. Further, an image convolutional neural network (CNN), ResNet network,
and a quantum CNN were assessed on the power spectral images as additional
validation tools. All image-based CNNs exhibited a nearly equal classification
performance with an accuracy of roughly 82% and reasonably high sensitivity and
specificity scores. Our pilot study demonstrates that AI-algorithms coupled to
time-resolved FCS power spectra can accurately and differentially classify the
complex patient-derived EVs from different cancer samples of distinct tissue
subtypes.
",a
"Deep Learning for Interference Identification: Band, Training SNR, and
  Sample Selection","  We study the problem of interference source identification, through the lens
of recognizing one of 15 different channels that belong to 3 different wireless
technologies: Bluetooth, Zigbee, and WiFi. We employ deep learning algorithms
trained on received samples taken from a 10 MHz band in the 2.4 GHz ISM Band.
We obtain a classification accuracy of around 89.5% using any of four different
deep neural network architectures: CNN, ResNet, CLDNN, and LSTM, which
demonstrate the generality of the effectiveness of deep learning at the
considered task. Interestingly, our proposed CNN architecture requires
approximately 60% of the training time required by the state of the art while
achieving slightly larger classification accuracy. We then focus on the CNN
architecture and further optimize its training time while incurring minimal
loss in classification accuracy using three different approaches: 1- Band
Selection, where we only use samples belonging to the lower and uppermost 2 MHz
bands, 2- SNR Selection, where we only use training samples belonging to a
single SNR value, and 3- Sample Selection, where we try various sub-Nyquist
sampling methods to select the subset of samples most relevant to the
classification task. Our results confirm the feasibility of fast deep learning
for wireless interference identification, by showing that the training time can
be reduced by as much as 30x with minimal loss in accuracy.
",a
"Detection of prostate cancer in whole-slide images through end-to-end
  training with image-level labels","  Prostate cancer is the most prevalent cancer among men in Western countries,
with 1.1 million new diagnoses every year. The gold standard for the diagnosis
of prostate cancer is a pathologists' evaluation of prostate tissue.
  To potentially assist pathologists deep-learning-based cancer detection
systems have been developed. Many of the state-of-the-art models are
patch-based convolutional neural networks, as the use of entire scanned slides
is hampered by memory limitations on accelerator cards. Patch-based systems
typically require detailed, pixel-level annotations for effective training.
However, such annotations are seldom readily available, in contrast to the
clinical reports of pathologists, which contain slide-level labels. As such,
developing algorithms which do not require manual pixel-wise annotations, but
can learn using only the clinical report would be a significant advancement for
the field.
  In this paper, we propose to use a streaming implementation of convolutional
layers, to train a modern CNN (ResNet-34) with 21 million parameters end-to-end
on 4712 prostate biopsies. The method enables the use of entire biopsy images
at high-resolution directly by reducing the GPU memory requirements by 2.4 TB.
We show that modern CNNs, trained using our streaming approach, can extract
meaningful features from high-resolution images without additional heuristics,
reaching similar performance as state-of-the-art patch-based and
multiple-instance learning methods. By circumventing the need for manual
annotations, this approach can function as a blueprint for other tasks in
histopathological diagnosis.
  The source code to reproduce the streaming models is available at
https://github.com/DIAGNijmegen/pathology-streaming-pipeline .
",a
AFINet: Attentive Feature Integration Networks for Image Classification,"  Convolutional Neural Networks (CNNs) have achieved tremendous success in a
number of learning tasks including image classification. Recent advanced models
in CNNs, such as ResNets, mainly focus on the skip connection to avoid gradient
vanishing. DenseNet designs suggest creating additional bypasses to transfer
features as an alternative strategy in network design. In this paper, we design
Attentive Feature Integration (AFI) modules, which are widely applicable to
most recent network architectures, leading to new architectures named AFI-Nets.
AFI-Nets explicitly model the correlations among different levels of features
and selectively transfer features with a little overhead.AFI-ResNet-152 obtains
a 1.24% relative improvement on the ImageNet dataset while decreases the FLOPs
by about 10% and the number of parameters by about 9.2% compared to ResNet-152.
",a
AFINets: Attentive Feature Integration Networks for Image Classification,"Convolutional Neural Networks (CNNs) have achieved tremendous success in a number of learning tasks, e.g., image classification. Recent advances in CNNs, such as ResNets and DenseNets, mainly focus on the skip and concatenation operators to avoid gradient vanishing. However, such operators largely neglect information across layers (as in ResNets) or involve tremendous redundancy of features repeatedly copied from previous layers (as in DenseNets). In this paper, we design Attentive Feature Integration (AFI) modules, which can be applicable to most recent network architectures, leading to new architectures named as AFINets.  AFINets can by adaptively integrate distinct information through explicitly modeling the subordinate relationship between different levels of features. Experimental results on benchmark datasets have demonstrated the effectiveness of the proposed AFI modules.  
",p
"Backdooring Convolutional Neural Networks via Targeted Weight
  Perturbations","  We present a new type of backdoor attack that exploits a vulnerability of
convolutional neural networks (CNNs) that has been previously unstudied. In
particular, we examine the application of facial recognition. Deep learning
techniques are at the top of the game for facial recognition, which means they
have now been implemented in many production-level systems. Alarmingly, unlike
other commercial technologies such as operating systems and network devices,
deep learning-based facial recognition algorithms are not presently designed
with security requirements or audited for security vulnerabilities before
deployment. Given how young the technology is and how abstract many of the
internal workings of these algorithms are, neural network-based facial
recognition systems are prime targets for security breaches. As more and more
of our personal information begins to be guarded by facial recognition (e.g.,
the iPhone X), exploring the security vulnerabilities of these systems from a
penetration testing standpoint is crucial. Along these lines, we describe a
general methodology for backdooring CNNs via targeted weight perturbations.
Using a five-layer CNN and ResNet-50 as case studies, we show that an attacker
is able to significantly increase the chance that inputs they supply will be
falsely accepted by a CNN while simultaneously preserving the error rates for
legitimate enrolled classes.
",a
Web image search engine based on LSH index and CNN Resnet50,"  To implement a good Content Based Image Retrieval (CBIR) system, it is
essential to adopt efficient search methods. One way to achieve this results is
by exploiting approximate search techniques. In fact, when we deal with very
large collections of data, using an exact search method makes the system very
slow. In this project, we adopt the Locality Sensitive Hashing (LSH) index to
implement a CBIR system that allows us to perform fast similarity search on
deep features. Specifically, we exploit transfer learning techniques to extract
deep features from images; this phase is done using two famous Convolutional
Neural Networks (CNNs) as features extractors: Resnet50 and Resnet50v2, both
pre-trained on ImageNet. Then we try out several fully connected deep neural
networks, built on top of both of the previously mentioned CNNs in order to
fine-tuned them on our dataset. In both of previous cases, we index the
features within our LSH index implementation and within a sequential scan, to
better understand how much the introduction of the index affects the results.
Finally, we carry out a performance analysis: we evaluate the relevance of the
result set, computing the mAP (mean Average Precision) value obtained during
the different experiments with respect to the number of done comparison and
varying the hyper-parameter values of the LSH index.
",a
Towards Effective 2-bit Quantization: Pareto-optimal Bit Allocation for Deep CNNs Compression,"State-of-the-art quantization methods can compress deep neural networks down to 4 bits without losing accuracy. However, when it comes to 2 bits, the performance drop is still noticeable. One problem in these methods is that they assign equal bit rate to quantize weights and activations in all layers, which is not reasonable in the case of high rate compression (such as 2-bit quantization), as some of layers in deep neural networks are sensitive to quantization and performing coarse quantization on these layers can hurt the accuracy. In this paper, we address an important problem of how to optimize the bit allocation of weights and activations for deep CNNs compression. We first explore the additivity of output error caused by quantization and find that additivity property holds for deep neural networks which are continuously differentiable in the layers. Based on this observation, we formulate the optimal bit allocation problem of weights and activations in a joint framework and propose a very efficient method to solve the optimization problem via Lagrangian Formulation. Our method obtains excellent results on deep neural networks. It can compress deep CNN ResNet-50 down to 2 bits with only 0.7% accuracy loss. To the best our knowledge, this is the first paper that reports 2-bit results on deep CNNs without hurting the accuracy.",p
"On the role of feedback in visual processing: a predictive coding
  perspective","  Brain-inspired machine learning is gaining increasing consideration,
particularly in computer vision. Several studies investigated the inclusion of
top-down feedback connections in convolutional networks; however, it remains
unclear how and when these connections are functionally helpful. Here we
address this question in the context of object recognition under noisy
conditions. We consider deep convolutional networks (CNNs) as models of
feed-forward visual processing and implement Predictive Coding (PC) dynamics
through feedback connections (predictive feedback) trained for reconstruction
or classification of clean images. To directly assess the computational role of
predictive feedback in various experimental situations, we optimize and
interpret the hyper-parameters controlling the network's recurrent dynamics.
That is, we let the optimization process determine whether top-down connections
and predictive coding dynamics are functionally beneficial. Across different
model depths and architectures (3-layer CNN, ResNet18, and EfficientNetB0) and
against various types of noise (CIFAR100-C), we find that the network
increasingly relies on top-down predictions as the noise level increases; in
deeper networks, this effect is most prominent at lower layers. In addition,
the accuracy of the network implementing PC dynamics significantly increases
over time-steps, compared to its equivalent forward network. All in all, our
results provide novel insights relevant to Neuroscience by confirming the
computational role of feedback connections in sensory systems, and to Machine
Learning by revealing how these can improve the robustness of current vision
models.
",a
