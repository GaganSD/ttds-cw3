{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9498\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>keyword</th>\n",
       "      <th>description</th>\n",
       "      <th>totalDownloads</th>\n",
       "      <th>totalViews</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>ownerUser</th>\n",
       "      <th>dataset_slug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Bachelor Contestants</td>\n",
       "      <td>This dataset contains information about past s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>\\n### About this dataset\\n&amp;gt; &lt;p&gt;Creating a b...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>yamqwe</td>\n",
       "      <td>the-bachelor-contestantse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mineral photos</td>\n",
       "      <td>+39,000 images of mineral stored in 15 categories</td>\n",
       "      <td>['arts and entertainment']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>floriangeillon</td>\n",
       "      <td>mineral-photos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deepwater Ports</td>\n",
       "      <td>A Dataset of the Deepwater Port Licensing Program</td>\n",
       "      <td>['business', 'transportation', 'water transport']</td>\n",
       "      <td>\\n### About this dataset\\n&amp;gt; &lt;p&gt;&lt;strong&gt;The ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>yamqwe</td>\n",
       "      <td>deepwater-portse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ubiquant_train_target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>goweiting</td>\n",
       "      <td>ubiquant-train-target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>easy_firefly_weights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>tejaschaudhari2811</td>\n",
       "      <td>easy-firefly-weights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>Stanford Earthquake Dataset (STEAD)</td>\n",
       "      <td>A Global Data Set of Seismic Signals for AI</td>\n",
       "      <td>['earth science', 'geology', 'physics', 'signa...</td>\n",
       "      <td># Properties of the dataset\\nSTEAD includes tw...</td>\n",
       "      <td>31</td>\n",
       "      <td>505</td>\n",
       "      <td>5</td>\n",
       "      <td>isevilla</td>\n",
       "      <td>stanford-earthquake-dataset-stead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9494</th>\n",
       "      <td>Asphalt Cracks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>abrahamanderson</td>\n",
       "      <td>asphalt-cracks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>Maternal Health Risk Data</td>\n",
       "      <td>Predicting health risks for pregnant patients</td>\n",
       "      <td>['healthcare', 'public health', 'health', 'reg...</td>\n",
       "      <td>### Context\\n\\n Data has been collected from d...</td>\n",
       "      <td>519</td>\n",
       "      <td>4103</td>\n",
       "      <td>19</td>\n",
       "      <td>csafrit2</td>\n",
       "      <td>maternal-health-risk-data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9496</th>\n",
       "      <td>Medical Personal Protective Equipment Images</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['medicine', 'image data', 'covid19']</td>\n",
       "      <td>### Context\\n\\nCPPE - 5 (Medical Personal Prot...</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>skaarface</td>\n",
       "      <td>medical-personal-protective-equipment-images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497</th>\n",
       "      <td>Higher Education Students Performance Evaluation</td>\n",
       "      <td>Machine Learning Prediction Analysis</td>\n",
       "      <td>['research', 'education', 'multiclass classifi...</td>\n",
       "      <td>###Abstract###\\n\\nThe data was collected from ...</td>\n",
       "      <td>1357</td>\n",
       "      <td>8231</td>\n",
       "      <td>31</td>\n",
       "      <td>csafrit2</td>\n",
       "      <td>higher-education-students-performance-evaluation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9498 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                              The Bachelor Contestants   \n",
       "1                                        Mineral photos   \n",
       "2                                       Deepwater Ports   \n",
       "3                                 ubiquant_train_target   \n",
       "4                                  easy_firefly_weights   \n",
       "...                                                 ...   \n",
       "9493                Stanford Earthquake Dataset (STEAD)   \n",
       "9494                                     Asphalt Cracks   \n",
       "9495                          Maternal Health Risk Data   \n",
       "9496       Medical Personal Protective Equipment Images   \n",
       "9497   Higher Education Students Performance Evaluation   \n",
       "\n",
       "                                               subtitle  \\\n",
       "0     This dataset contains information about past s...   \n",
       "1     +39,000 images of mineral stored in 15 categories   \n",
       "2     A Dataset of the Deepwater Port Licensing Program   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "9493        A Global Data Set of Seismic Signals for AI   \n",
       "9494                                                NaN   \n",
       "9495      Predicting health risks for pregnant patients   \n",
       "9496                                                NaN   \n",
       "9497               Machine Learning Prediction Analysis   \n",
       "\n",
       "                                                keyword  \\\n",
       "0                                                    []   \n",
       "1                            ['arts and entertainment']   \n",
       "2     ['business', 'transportation', 'water transport']   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "9493  ['earth science', 'geology', 'physics', 'signa...   \n",
       "9494                                                 []   \n",
       "9495  ['healthcare', 'public health', 'health', 'reg...   \n",
       "9496              ['medicine', 'image data', 'covid19']   \n",
       "9497  ['research', 'education', 'multiclass classifi...   \n",
       "\n",
       "                                            description  totalDownloads  \\\n",
       "0     \\n### About this dataset\\n&gt; <p>Creating a b...               0   \n",
       "1                                                   NaN               5   \n",
       "2     \\n### About this dataset\\n&gt; <p><strong>The ...               1   \n",
       "3                                                   NaN               0   \n",
       "4                                                   NaN               0   \n",
       "...                                                 ...             ...   \n",
       "9493  # Properties of the dataset\\nSTEAD includes tw...              31   \n",
       "9494                                                NaN               2   \n",
       "9495  ### Context\\n\\n Data has been collected from d...             519   \n",
       "9496  ### Context\\n\\nCPPE - 5 (Medical Personal Prot...               3   \n",
       "9497  ###Abstract###\\n\\nThe data was collected from ...            1357   \n",
       "\n",
       "      totalViews  totalVotes           ownerUser  \\\n",
       "0              5           1              yamqwe   \n",
       "1             31           0      floriangeillon   \n",
       "2              7           1              yamqwe   \n",
       "3              1           0           goweiting   \n",
       "4             19           0  tejaschaudhari2811   \n",
       "...          ...         ...                 ...   \n",
       "9493         505           5            isevilla   \n",
       "9494          46           0     abrahamanderson   \n",
       "9495        4103          19            csafrit2   \n",
       "9496          95           3           skaarface   \n",
       "9497        8231          31            csafrit2   \n",
       "\n",
       "                                          dataset_slug  \n",
       "0                            the-bachelor-contestantse  \n",
       "1                                       mineral-photos  \n",
       "2                                     deepwater-portse  \n",
       "3                                ubiquant-train-target  \n",
       "4                                 easy-firefly-weights  \n",
       "...                                                ...  \n",
       "9493                 stanford-earthquake-dataset-stead  \n",
       "9494                                    asphalt-cracks  \n",
       "9495                         maternal-health-risk-data  \n",
       "9496      medical-personal-protective-equipment-images  \n",
       "9497  higher-education-students-performance-evaluation  \n",
       "\n",
       "[9498 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "kaggle_df = pd.read_csv('kaggle_dataset_df_page500.csv')\n",
    "print(kaggle_df.shape[0])\n",
    "kaggle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5627\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>owner</th>\n",
       "      <th>date</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>keywords</th>\n",
       "      <th>#downloads</th>\n",
       "      <th>#views</th>\n",
       "      <th>#votes</th>\n",
       "      <th>dataset_slug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>The **MNIST** database (**Modified National In...</td>\n",
       "      <td>https://paperswithcode.com/dataset/mnist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CelebA</td>\n",
       "      <td>CelebFaces Attributes dataset contains 202,599...</td>\n",
       "      <td>https://paperswithcode.com/dataset/celeba</td>\n",
       "      <td>01/01/2015</td>\n",
       "      <td>CelebFaces Attributes Dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JFT-300M</td>\n",
       "      <td>**JFT-300M** is an internal Google dataset use...</td>\n",
       "      <td>https://paperswithcode.com/dataset/jft-300m</td>\n",
       "      <td>10/07/2017</td>\n",
       "      <td>JFT-300M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLUE</td>\n",
       "      <td>General Language Understanding Evaluation (**G...</td>\n",
       "      <td>https://paperswithcode.com/dataset/glue</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>General Language Understanding Evaluation benc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultiNLI</td>\n",
       "      <td>The **Multi-Genre Natural Language Inference**...</td>\n",
       "      <td>https://paperswithcode.com/dataset/multinli</td>\n",
       "      <td>01/01/2018</td>\n",
       "      <td>Multi-Genre Natural Language Inference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>Dataset for the Article \"Does the Venue of Sci...</td>\n",
       "      <td>Is there any correlation between the impact of...</td>\n",
       "      <td>https://paperswithcode.com/dataset/dataset-for...</td>\n",
       "      <td>31/05/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5623</th>\n",
       "      <td>WSJ Dow Jones Stock Data</td>\n",
       "      <td>Please see code repository. [https://github.co...</td>\n",
       "      <td>https://paperswithcode.com/dataset/wsj-dow-jon...</td>\n",
       "      <td>15/02/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624</th>\n",
       "      <td>ZInd</td>\n",
       "      <td>The Zillow Indoor Dataset (ZInD) provides exte...</td>\n",
       "      <td>https://paperswithcode.com/dataset/zind</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zillow Indoor Dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>IMDB-Clean</td>\n",
       "      <td>We have cleaned the noisy IMDB-WIKI dataset us...</td>\n",
       "      <td>https://paperswithcode.com/dataset/imdb-clean</td>\n",
       "      <td>21/06/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>TriggerCit 2021 Thailand / Nepal floods</td>\n",
       "      <td>Twitter dataset related to flood events onsets...</td>\n",
       "      <td>https://paperswithcode.com/dataset/triggercit-...</td>\n",
       "      <td>24/02/2022</td>\n",
       "      <td>Twitter dataset of flood-related images for Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5627 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                                                 MNIST   \n",
       "1                                                CelebA   \n",
       "2                                              JFT-300M   \n",
       "3                                                  GLUE   \n",
       "4                                              MultiNLI   \n",
       "...                                                 ...   \n",
       "5622  Dataset for the Article \"Does the Venue of Sci...   \n",
       "5623                           WSJ Dow Jones Stock Data   \n",
       "5624                                               ZInd   \n",
       "5625                                         IMDB-Clean   \n",
       "5626            TriggerCit 2021 Thailand / Nepal floods   \n",
       "\n",
       "                                            description  \\\n",
       "0     The **MNIST** database (**Modified National In...   \n",
       "1     CelebFaces Attributes dataset contains 202,599...   \n",
       "2     **JFT-300M** is an internal Google dataset use...   \n",
       "3     General Language Understanding Evaluation (**G...   \n",
       "4     The **Multi-Genre Natural Language Inference**...   \n",
       "...                                                 ...   \n",
       "5622  Is there any correlation between the impact of...   \n",
       "5623  Please see code repository. [https://github.co...   \n",
       "5624  The Zillow Indoor Dataset (ZInD) provides exte...   \n",
       "5625  We have cleaned the noisy IMDB-WIKI dataset us...   \n",
       "5626  Twitter dataset related to flood events onsets...   \n",
       "\n",
       "                                                  owner        date  \\\n",
       "0              https://paperswithcode.com/dataset/mnist         NaN   \n",
       "1             https://paperswithcode.com/dataset/celeba  01/01/2015   \n",
       "2           https://paperswithcode.com/dataset/jft-300m  10/07/2017   \n",
       "3               https://paperswithcode.com/dataset/glue  01/01/2019   \n",
       "4           https://paperswithcode.com/dataset/multinli  01/01/2018   \n",
       "...                                                 ...         ...   \n",
       "5622  https://paperswithcode.com/dataset/dataset-for...  31/05/2021   \n",
       "5623  https://paperswithcode.com/dataset/wsj-dow-jon...  15/02/2022   \n",
       "5624            https://paperswithcode.com/dataset/zind         NaN   \n",
       "5625      https://paperswithcode.com/dataset/imdb-clean  21/06/2021   \n",
       "5626  https://paperswithcode.com/dataset/triggercit-...  24/02/2022   \n",
       "\n",
       "                                               subtitle  keywords  #downloads  \\\n",
       "0                                                   NaN       NaN         NaN   \n",
       "1                         CelebFaces Attributes Dataset       NaN         NaN   \n",
       "2                                              JFT-300M       NaN         NaN   \n",
       "3     General Language Understanding Evaluation benc...       NaN         NaN   \n",
       "4                Multi-Genre Natural Language Inference       NaN         NaN   \n",
       "...                                                 ...       ...         ...   \n",
       "5622                                                NaN       NaN         NaN   \n",
       "5623                                                NaN       NaN         NaN   \n",
       "5624                              Zillow Indoor Dataset       NaN         NaN   \n",
       "5625                                                NaN       NaN         NaN   \n",
       "5626  Twitter dataset of flood-related images for Se...       NaN         NaN   \n",
       "\n",
       "      #views  #votes  dataset_slug  \n",
       "0        NaN     NaN           NaN  \n",
       "1        NaN     NaN           NaN  \n",
       "2        NaN     NaN           NaN  \n",
       "3        NaN     NaN           NaN  \n",
       "4        NaN     NaN           NaN  \n",
       "...      ...     ...           ...  \n",
       "5622     NaN     NaN           NaN  \n",
       "5623     NaN     NaN           NaN  \n",
       "5624     NaN     NaN           NaN  \n",
       "5625     NaN     NaN           NaN  \n",
       "5626     NaN     NaN           NaN  \n",
       "\n",
       "[5627 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperwithcode_df = pd.read_csv('paperwithcode_df.csv')\n",
    "print(paperwithcode_df.shape[0])\n",
    "paperwithcode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>description</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Covid_19_Analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Covid19casesMalaysia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID19_CT_7930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid19_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>covid-190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>covid_19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>covid_470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>covid19deta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Covid19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title  subtitle  description  Source\n",
       "0     Covid_19_Analysis       NaN          NaN  Kaggle\n",
       "1  Covid19casesMalaysia       NaN          NaN  Kaggle\n",
       "2               covid19       NaN          NaN  Kaggle\n",
       "3       COVID19_CT_7930       NaN          NaN  Kaggle\n",
       "4             covid19_3       NaN          NaN  Kaggle\n",
       "5             covid-190       NaN          NaN  Kaggle\n",
       "6              covid_19       NaN          NaN  Kaggle\n",
       "7             covid_470       NaN          NaN  Kaggle\n",
       "8           covid19deta       NaN          NaN  Kaggle\n",
       "9               Covid19       NaN          NaN  Kaggle"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_res_covid_2021 = pd.read_csv('bm_25_result_df_covid_2021.csv')\n",
    "tfidf_res_covid_2021 = pd.read_csv('tfidf_result_df_covid_2021.csv')\n",
    "bm25_res_covid_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>description</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID-QU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>### COVID-QU-Ex Dataset\\nThe researchers of Qa...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Huge Dataset - COVID 19 worldwide case</td>\n",
       "      <td>COVID 19 dataset from Jan 28, 2020  to Jan 8, ...</td>\n",
       "      <td>### Context\\n\\nThe dataset contains COVID 19 d...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-19 India Dataset @ IndoML 2021</td>\n",
       "      <td>Detailed COVID-19 Data from Daily Health Bulle...</td>\n",
       "      <td># COVID-19 Datathon @ IndoML 2021\\n\\nThe COVID...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Proyecto 1: Exceso de Muertes por COVID19</td>\n",
       "      <td>Realiza una estimación de las muertes por COVI...</td>\n",
       "      <td>### Introducción\\n\\nEn este proyecto realizará...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID-19 Tracking Germany</td>\n",
       "      <td>Daily Updated Cases &amp; Deaths - Augmented with ...</td>\n",
       "      <td>Read the [associated blogpost](https://heads0r...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COVID19_datasets</td>\n",
       "      <td>COVID-19 datasets obtained from github.com/nyt...</td>\n",
       "      <td>Collected COVID-19 datasets from various sourc...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICC T20 World Cup 2021 Tweets 🏏</td>\n",
       "      <td>Explore the tweets made by fans with the #T20W...</td>\n",
       "      <td>\\n![](https://www.timesofsports.com/wp-content...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COVID-19 Indonesia Dataset (Case and Vaccination)</td>\n",
       "      <td>COVID-19 Daily Case and Vaccination Progress  ...</td>\n",
       "      <td>### Context\\n\\nSince the first time the Covid ...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Covid-19 in Singapore : Latest Detailed Data</td>\n",
       "      <td>Latest and regularly updated covid 19 in Singa...</td>\n",
       "      <td>### Latest Covid 19 Data of Singapore \\n\\nData...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>covid-19 data of india</td>\n",
       "      <td>Weekly/Dialy Updated covid-19 dataset of india</td>\n",
       "      <td>[![forthebadge](https://forthebadge.com/images...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                          COVID-QU    \n",
       "1             Huge Dataset - COVID 19 worldwide case   \n",
       "2               COVID-19 India Dataset @ IndoML 2021   \n",
       "3          Proyecto 1: Exceso de Muertes por COVID19   \n",
       "4                          COVID-19 Tracking Germany   \n",
       "5                                   COVID19_datasets   \n",
       "6                    ICC T20 World Cup 2021 Tweets 🏏   \n",
       "7  COVID-19 Indonesia Dataset (Case and Vaccination)   \n",
       "8       Covid-19 in Singapore : Latest Detailed Data   \n",
       "9                             covid-19 data of india   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0                                                NaN   \n",
       "1  COVID 19 dataset from Jan 28, 2020  to Jan 8, ...   \n",
       "2  Detailed COVID-19 Data from Daily Health Bulle...   \n",
       "3  Realiza una estimación de las muertes por COVI...   \n",
       "4  Daily Updated Cases & Deaths - Augmented with ...   \n",
       "5  COVID-19 datasets obtained from github.com/nyt...   \n",
       "6  Explore the tweets made by fans with the #T20W...   \n",
       "7  COVID-19 Daily Case and Vaccination Progress  ...   \n",
       "8  Latest and regularly updated covid 19 in Singa...   \n",
       "9     Weekly/Dialy Updated covid-19 dataset of india   \n",
       "\n",
       "                                         description  Source  \n",
       "0  ### COVID-QU-Ex Dataset\\nThe researchers of Qa...  Kaggle  \n",
       "1  ### Context\\n\\nThe dataset contains COVID 19 d...  Kaggle  \n",
       "2  # COVID-19 Datathon @ IndoML 2021\\n\\nThe COVID...  Kaggle  \n",
       "3  ### Introducción\\n\\nEn este proyecto realizará...  Kaggle  \n",
       "4  Read the [associated blogpost](https://heads0r...  Kaggle  \n",
       "5  Collected COVID-19 datasets from various sourc...  Kaggle  \n",
       "6  \\n![](https://www.timesofsports.com/wp-content...  Kaggle  \n",
       "7  ### Context\\n\\nSince the first time the Covid ...  Kaggle  \n",
       "8  ### Latest Covid 19 Data of Singapore \\n\\nData...  Kaggle  \n",
       "9  [![forthebadge](https://forthebadge.com/images...  Kaggle  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_res_covid_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>description</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Foods Dataset</td>\n",
       "      <td>Foods from SEA region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reviews</td>\n",
       "      <td>Classify using user reviews</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>food-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDONESIAN FOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reviews</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>review</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Italian Food Recipes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>food101_tfrecords</td>\n",
       "      <td>A dataset of 101 food categories with 101000 i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amazon Fine Foods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon Fine Foods is a dataset that consists o...</td>\n",
       "      <td>Paper_with_code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                           subtitle  \\\n",
       "0          Foods Dataset                              Foods from SEA region   \n",
       "1                Reviews                        Classify using user reviews   \n",
       "2                food-11                                                NaN   \n",
       "3        INDONESIAN FOOD                                                NaN   \n",
       "4          Food Delivery                                                NaN   \n",
       "5                reviews                                                NaN   \n",
       "6                 review                                                NaN   \n",
       "7  Italian Food Recipes                                                 NaN   \n",
       "8      food101_tfrecords  A dataset of 101 food categories with 101000 i...   \n",
       "9      Amazon Fine Foods                                                NaN   \n",
       "\n",
       "                                         description           Source  \n",
       "0                                                NaN           Kaggle  \n",
       "1                                                NaN           Kaggle  \n",
       "2                                                NaN           Kaggle  \n",
       "3                                                NaN           Kaggle  \n",
       "4                                                NaN           Kaggle  \n",
       "5                                                NaN           Kaggle  \n",
       "6                                                NaN           Kaggle  \n",
       "7                                                NaN           Kaggle  \n",
       "8                                                NaN           Kaggle  \n",
       "9  Amazon Fine Foods is a dataset that consists o...  Paper_with_code  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_res_review_food = pd.read_csv('bm_25_result_df_review_food.csv')\n",
    "tfidf_res_review_food = pd.read_csv('tfidf_result_df_review_food.csv')\n",
    "bm25_res_review_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>description</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SemEval 2014 Task 4: AspectBasedSentimentAnalysis</td>\n",
       "      <td>SemEval-2014 ABSA Task is based on laptop and ...</td>\n",
       "      <td>Copied from [https://alt.qcri.org/semeval2014/...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon Fine Foods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon Fine Foods is a dataset that consists o...</td>\n",
       "      <td>Paper_with_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon Food</td>\n",
       "      <td>List of Amazon Food with UserId &amp; ProductId</td>\n",
       "      <td>### Context\\n\\nThis dataset consists of produc...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>⭐ McDonalds Review Sentiment</td>\n",
       "      <td>2000 collected samples, technical information</td>\n",
       "      <td>\\n### About this dataset\\n&amp;gt; &lt;p&gt;A sentiment ...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chocolate Ratings</td>\n",
       "      <td>Reviews on more than 2400 chocolate bars!</td>\n",
       "      <td># About this dataset :chocolate_bar:\\n&amp;gt; Cho...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Urdu Online Reviews</td>\n",
       "      <td>Urdu Online Reviews</td>\n",
       "      <td>This corpus was constructed by collecting 10,0...</td>\n",
       "      <td>Paper_with_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Affordability of Diets</td>\n",
       "      <td>Cost and affordability of nutritious diets acr...</td>\n",
       "      <td>\\n### About this dataset\\n&amp;gt; &lt;h2&gt;&lt;strong&gt;Abo...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>🍔 Fast Food Restaurants Across America</td>\n",
       "      <td>A list of 10,000 fast food restaurants provide...</td>\n",
       "      <td>\\n### About this dataset\\n&amp;gt; &lt;h1&gt;About This ...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Food2K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Food2K is a large food recognition dataset wit...</td>\n",
       "      <td>Paper_with_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Food Recognition 2022: Dataset</td>\n",
       "      <td>Detecting &amp; Segmenting various kinds of food f...</td>\n",
       "      <td>\\n# 🍕 Food Recognition 2022\\n\\n## Problem Stat...</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  SemEval 2014 Task 4: AspectBasedSentimentAnalysis   \n",
       "1                                  Amazon Fine Foods   \n",
       "2                                        Amazon Food   \n",
       "3                       ⭐ McDonalds Review Sentiment   \n",
       "4                                  Chocolate Ratings   \n",
       "5                                Urdu Online Reviews   \n",
       "6                             Affordability of Diets   \n",
       "7             🍔 Fast Food Restaurants Across America   \n",
       "8                                             Food2K   \n",
       "9                     Food Recognition 2022: Dataset   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0  SemEval-2014 ABSA Task is based on laptop and ...   \n",
       "1                                                NaN   \n",
       "2        List of Amazon Food with UserId & ProductId   \n",
       "3      2000 collected samples, technical information   \n",
       "4          Reviews on more than 2400 chocolate bars!   \n",
       "5                                Urdu Online Reviews   \n",
       "6  Cost and affordability of nutritious diets acr...   \n",
       "7  A list of 10,000 fast food restaurants provide...   \n",
       "8                                                NaN   \n",
       "9  Detecting & Segmenting various kinds of food f...   \n",
       "\n",
       "                                         description           Source  \n",
       "0  Copied from [https://alt.qcri.org/semeval2014/...           Kaggle  \n",
       "1  Amazon Fine Foods is a dataset that consists o...  Paper_with_code  \n",
       "2  ### Context\\n\\nThis dataset consists of produc...           Kaggle  \n",
       "3  \\n### About this dataset\\n&gt; <p>A sentiment ...           Kaggle  \n",
       "4  # About this dataset :chocolate_bar:\\n&gt; Cho...           Kaggle  \n",
       "5  This corpus was constructed by collecting 10,0...  Paper_with_code  \n",
       "6  \\n### About this dataset\\n&gt; <h2><strong>Abo...           Kaggle  \n",
       "7  \\n### About this dataset\\n&gt; <h1>About This ...           Kaggle  \n",
       "8  Food2K is a large food recognition dataset wit...  Paper_with_code  \n",
       "9  \\n# 🍕 Food Recognition 2022\\n\\n## Problem Stat...           Kaggle  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_res_review_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
